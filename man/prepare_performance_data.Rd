% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prepare_performance_data.R
\name{prepare_performance_data}
\alias{prepare_performance_data}
\title{Prepare Performance Data}
\usage{
prepare_performance_data(
  probs,
  real,
  by = 0.01,
  stratified_by = "probability_threshold"
)
}
\arguments{
\item{probs}{a vector of estimated probabilities or a list of vectors of that
kind (one for each model)}

\item{real}{a vector of binary outcomes or a list of vectors of that
kind (one for each population)}

\item{by}{number: increment of the sequence.}

\item{stratified_by}{Performance Metrics can be stratified by Probability
Threshold or alternatively by Predicted Positives Condition Rate}
}
\description{
The prepare_performance_data function makes a Performance Data that is made
of different cutoffs.
Each row represents a cutoff and each column stands for a performance metric.
It is possible to use this function for more than one model in order to
compare different models performance for the same population.
In this case the user should use a list that is made of vectors of estimated
probabilities, one for each model.
}
\details{
Sometime instead of using a cutoff for the estimated probability it
is required to enforce a symmetry between the percentiles of the
probabilities, in medicine it is referred as "Risk Percentile" when the
outcome stands for something negative in essence such as a severe disease
or death: Let's say that we want to see the model performance for the top 5\%
patients at risk for some well defined population, in this case the user
should change the parameter stratified_by from the default
"probability_threshold" to "predicted_positives" and the results will be
similar Performance Data,
only this time each row will represent some rounded percentile.
}
\examples{
# You can prepare Performance Data for one model

prepare_performance_data(
  probs = example_dat$estimated_probabilities,
  real = example_dat$outcome
)

# And you can prepare Performance Data for more than one model
prepare_performance_data(
  probs = list(
    "First Model" = example_dat$estimated_probabilities,
    "Second Model" = example_dat$random_guess
  ),
  real = example_dat$outcome
)

# Notice that once you've put a list in the probs parameter you'll
# receive a new
# column in the Performance Data named "Model". If it's a named list
# (like in our
# example) the Model column will mention the names of each element
# in the probs-list
# as the name of the model, if it's unnamed list the Models will count
# "Model 1",
# "Model 2", etc.. according to the order of the estimated-probabilities
# vector in the
# list.


prepare_performance_data(
  probs = list(
    "train" = example_dat \%>\%
      dplyr::filter(type_of_set == "train") \%>\%
      dplyr::pull(estimated_probabilities),
    "test" = example_dat \%>\% dplyr::filter(type_of_set == "test") \%>\%
      dplyr::pull(estimated_probabilities)
  ),
  real = list(
    "train" = example_dat \%>\% dplyr::filter(type_of_set == "train") \%>\%
      dplyr::pull(outcome),
    "test" = example_dat \%>\% dplyr::filter(type_of_set == "test") \%>\%
      dplyr::pull(outcome)
  )
)
}
