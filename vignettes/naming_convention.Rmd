---
title: "Naming Convention"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Naming Convention}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(rtichoke)
```

## [**Types of Inputs**]{.ul}

There are two types of inputs for each function in {rtichoke}:

1.  **Predictions and Outcomes:\
    **This type of input is similar to inputs from similar packages such as pROC etc.\
    You can do so in three different ways:

    -   A vector of predictions and a vector of outcome:\
        When you have one model and one population
    -   A list of predictions and a vector of outcomes:\
        When you have several models and one population.
    -   A list of predictions and a list of outcomes:\
        When you have several models and several populations, one model for each population.\
        Like in Train-Test comparison in order to asses if the model is underfitted or overfitted, or analysis of Fairness in order to check subgroups in a bigger population.\

    Each function in `rtichoke` has a variation that supports this kind of input.\

2.  **Performance Data:**

    Performance Data is a dataframe that contations perfomance metrics for different cutoffs.

    Similar packages to \`rtichoke\` display curves that are based on performance metrics that looks perfectly smooth, the purpose of rtichoke

    is slightly different: The aim is to help the user to better identify the relationship between the cutoffs and to give him the freedom to

    manipulate in order to understand better the connection between the cutoffs and the curve.

    Another reason for using Performance Data is that building plots that based on small datasets is much less memory consuming than reusing

    smoothing algorithms over and over.\\

    Each Performance Data is built from the metrics in the confusion matrix:

    TP, FP, TN, FN.

    sensitivity = TP / (TP + FN)

    specificity = TN / (TN + FP)

    \\

    In order to prepare Performance Data you need to call \`prepare_performance_data()\`This function obviously must take \*\*Predictions and Outcomes\*\* as input.

    Only some functions in \`rtichoke\` has variations that supports this kind of input

## [**Naming Convention**]{.ul}

Some of the functions in `rtichoke` are built to work with an object that is called "performance_data" - a data frame that includes different performance metrics for different cutoffs.

But other functions are built to work estimated probabilities and outcomes. Each of these function starts with "create" (as create from scratch) - create\_\*():

```{r echo=FALSE}

tibble::tribble(~"Output", ~"Predictions and Outcomes", ~"Performance Data",

                "Performance Data", "`prepare_performance_data()`", "",

                "ROC", "`create_roc_curve()`", "`plot_roc_curve()`",

                "Lift", "`create_lift_curve()`", "`plot_lift_curve()`",

                "Gains", "`create_gains_curve()`", "`plot_gains_curve()`",

                "Precision Recall", "`create_precision_recall_curve()`", "`plot_precision_recall_curve()`",

                "Decision", "`create_decision_curve()`", "`plot_decision_curve()`",

                "Calibration", "`create_calibration_curve()`", "",

                "Performance Table", "`create_performance_table()`", "`render_performance_table()`",

                "Summary Report", "`create_summary_report()`", "") %>%

  gt::gt(rowname_col = "Output")   %>%

  gt::fmt_markdown(columns = c("Predictions and Outcomes", "Performance Data"))  %>% 
  gt::tab_style(
    style = list(
      gt::cell_text(weight = "bold")
    ),
    locations = gt::cells_column_labels(dplyr::everything())
  )  %>% 
  gt::opt_table_lines(extent = "default") %>%
  gt::tab_options(
    column_labels.border.top.color = "white",
    column_labels.border.top.width = gt::px(3),
    column_labels.border.bottom.color = "black",
    table_body.hlines.color = "white",
    table.border.bottom.color = "white",
    table.border.bottom.width = gt::px(3)
  )

 

```

## [**Plots of Performance Metrics across different Thresholds**]{.ul}

Curves that are generated from performance metrics can be called by `plot_*_curve()` or `create_*_curve` from Performance Data.

```{r}
tibble::tribble(~"Curve", ~"Sens", ~"Spec", ~"PPV", ~"PPCR", ~"Lift", ~"NB", ~"P. Thr",
                "ROC","y", "x", " ", " ", " ", " ", " ",
                "Lift"," ", " ", " ", "x", "y", " ", " ",
                "Gains"," ", "y", " ", "x", " ", " ", " ",
                "Precision Recall","x", " ", "y", " ", " ", " ", " ",
                "Decision","x", " ", "y", " ", " ", "y", "x") %>% 
  gt::gt(rowname_col = "Curve")   %>%
  gt::tab_style(
    style = list(
      gt::cell_text(weight = "bold")
    ),
    locations = gt::cells_column_labels(dplyr::everything())
  )  %>% 
  gt::opt_table_lines(extent = "default") %>%
  gt::tab_options(
    column_labels.border.top.color = "white",
    column_labels.border.top.width = gt::px(3),
    column_labels.border.bottom.color = "black",
    table_body.hlines.color = "white",
    table.border.bottom.color = "white",
    table.border.bottom.width = gt::px(3)
  ) %>%
  gt::cols_align(
    align = "center"
  ) %>% 
  gt::cols_width(
    gt::everything() ~ px(100)
  )

 

```

+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+
|                      | Sensitivity | Specificity | FPR | PPV | Positive Rate | LIFT | Net     | Threshold |
|                      |             |             |     |     |               |      |         |           |
|                      |             |             |     |     |               |      | Benifit |           |
+======================+=============+=============+=====+=====+===============+======+=========+===========+
| **ROC**              | V           |             | V   |     |               |      |         |           |
+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+
| **Lift**             |             |             |     |     | V             | V    |         |           |
+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+
| **Gains**            | V           |             |     |     | V             |      |         |           |
+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+
| **Precision Recall** | V           |             |     | V   |               |      |         |           |
+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+
| **Decision**         |             |             |     |     |               |      | V       | V         |
+----------------------+-------------+-------------+-----+-----+---------------+------+---------+-----------+

[**Interactive or Non-Interactive**]{.ul}

Each plot of performance metrics in `rtichoke` has two versions:

1.  Interactive: a plotly object that displays a dynamic point that corresponds to a slider:
2.  Non Interactive: a ggplot2 object.

[**Why the curves aren't smooth?**]{.ul}

Unlike other packages rtichoke doesn't use a smoothed curve but a collection of connected dots, the justification for this type of ... is that most of the time 100 cutoff are enough.

Smoothing algorithms are expensive computationally, and specifically for this type of curves it might not give the user some useful insights. In fact smoothing can hide some useful information, such as the distribution of the cutoffs on the curves given a symmetry of threshold cutoffs or symmetry of probabilities percentiles {rephrase in a better way}.

Take a look at these two versions of the same ROC curve:

[**`by` argument:**]{.ul}

If the user wants to have a moother curve he can do so by change the `by` argument from the default 0.01 (like in the `seq` function):

```{r}
create_roc_curve(
 probs = example_dat$estimated_probabilities,
 real = example_dat$outcome, 
 by = 0.0001)

```

[**`stratified_by`argument:**]{.ul}

If the use wants to observe cutoffs according to probabilities percentiles he can do so by setting the `stratified_by` to `Probability Threshold`.

## [**Interactive Tables**]{.ul}

Interactive Performance Data is just a `reactable` object that wraps a Performance Data and returns an HTML object..

There are two advantages that are built in interactive tables:

1.  Conditional Styling - Each performance metric will be displayed with a light green in the background in case that more is better (Sensitivity, Specificity etc), or a light red if less is better (FPR). The color of the Net Benefit will be displayed in light green for positive values and in light red for negative values.
2.  Filter options with crosstalk - if `TRUE` returns a crosstalk object that let the user filter by model / population and main slider.

## [**Interactive Report**]{.ul}

## [**Calibration**]{.ul}

Plots a calibration curve

## [**rtichoke**]{.ul}
